---
description: Модели, токены, создание своей модели
globs: 
alwaysApply: true
---

# Модели и Токены

## Что такое токены модели

Токен — это кусочек текста
(слово, часть слова, символ).
Модель читает и генерирует токены.

Пример: "Привет мир" → ["При", "вет", " мир"]

Каждая модель имеет свой токенизатор.
Он разбивает текст на токены
и собирает обратно.

## Как генерируются токены

Мы НЕ создаём токены вручную.
Модель делает это сама:
1. Принимает текст (промпт)
2. Токенизатор разбивает на токены
3. Модель предсказывает следующий
4. Повторяет пока не закончит

Параметры генерации:
- max_new_tokens — сколько токенов
  максимум сгенерировать
- temperature — креативность
  (0.1 = точно, 1.0 = свободно)
- top_p — отсечка маловероятных
- do_sample — случайность выбора

## Стоимость токенов

На бесплатном CPU Basic:
- Ограничение по RAM (~16GB)
- Скорость зависит от модели
- Нет лимита на токены (своя модель)

На платном GPU Space:
- Быстрее в 10-50 раз
- Можно крупнее модель
- Оплата за время работы Space

Через Inference API (чужие модели):
- Бесплатный лимит: ~1000 запросов/день
- Платный: по токенам

## Своя модель — Да, можно!

### Что значит "своя модель"

Берём открытую базовую модель
и дообучаем (fine-tune) на своих данных.
Результат — модель, которая знает
наш мир Аллодов.

### Путь создания своей модели

```
1. Собрать данные
   - Описания мира Аллодов
   - Диалоги NPC
   - FAQ по механикам
   - Лор, квесты, предметы

2. Подготовить датасет
   - Формат: вопрос → ответ
   - Или: инструкция → выполнение
   - JSON / CSV / JSONL

3. Выбрать базовую модель
   - distilgpt2 (82M) — быстро
   - TinyLlama (1.1B) — умнее
   - Phi-2 (2.7B) — ещё умнее

4. Дообучить (fine-tune)
   - Метод: LoRA / QLoRA
   - Инструмент: HF Trainer
   - Где: Google Colab (бесплатно)
     или HF Training Space

5. Загрузить на HF Hub
   - Модель становится доступна
   - Можно использовать в Space
```

### Реальные сроки

- Сбор данных: 1-2 недели
- Подготовка датасета: 2-3 дня
- Fine-tune на Colab: 2-8 часов
- Тестирование: 1-2 дня

Даже медленно — это реально.
Первую версию можно сделать
за 2-3 недели.

### Инструменты для fine-tune

```python
# Минимальный пример (LoRA)
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
)
from peft import LoraConfig, get_peft_model
from datasets import load_dataset

# 1. Загружаем базу
model = AutoModelForCausalLM.from_pretrained(
    "distilgpt2"
)
tokenizer = AutoTokenizer.from_pretrained(
    "distilgpt2"
)

# 2. Настраиваем LoRA
lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["c_attn"],
    lora_dropout=0.05,
)
model = get_peft_model(model, lora_config)

# 3. Загружаем наш датасет
dataset = load_dataset(
    "json",
    data_files="allod_data.jsonl"
)

# 4. Обучаем
trainer = Trainer(
    model=model,
    train_dataset=dataset["train"],
    args=TrainingArguments(
        output_dir="./allod-model",
        num_train_epochs=3,
        per_device_train_batch_size=4,
    ),
)
trainer.train()

# 5. Сохраняем
model.save_pretrained("./allod-model")
tokenizer.save_pretrained("./allod-model")
```

### Формат датасета (пример)

```json
{"prompt": "Что такое Аллод?",
 "response": "Аллод — это остров,
  парящий в Астрале."}

{"prompt": "Как нанять армию?",
 "response": "Открой казарму,
  выбери тип юнита и нажми Нанять."}

{"prompt": "Кто такой Лорд?",
 "response": "Лорд — игровой аватар,
  управляющий армией и территорией."}
```

## Рекомендация

Начинаем с Фазы 1 (Советник):
- Берём готовую модель
- Прокачиваем промпт
- Параллельно собираем датасет
- Когда данных достаточно — fine-tune
- Получаем свою модель Аллода
